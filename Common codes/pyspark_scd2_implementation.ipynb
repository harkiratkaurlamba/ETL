{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c68a93ac-390d-4d1d-8300-3b8460097f1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE dim_entity (\n",
    "    dim_key     BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "    bk          STRING,\n",
    "    attr1       STRING,\n",
    "    attr2       STRING,\n",
    "    valid_from  TIMESTAMP,\n",
    "    valid_to    TIMESTAMP,\n",
    "    is_current  BOOLEAN\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "959c47fe-208e-45dd-a439-5bf0bb870078",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MERGE INTO dim_entity AS t\n",
    "USING src AS s\n",
    "ON  t.bk = s.bk\n",
    "AND t.is_current = true\n",
    "\n",
    "WHEN MATCHED \n",
    "     AND (\n",
    "          t.attr1 <> s.attr1\n",
    "       OR t.attr2 <> s.attr2\n",
    "       OR (t.attr1 IS NULL AND s.attr1 IS NOT NULL)\n",
    "       OR (t.attr1 IS NOT NULL AND s.attr1 IS NULL)\n",
    "       -- add comparisons for all tracked attributes\n",
    "     )\n",
    "THEN UPDATE SET\n",
    "    t.valid_to   = s.etl_run_ts,   -- or s.row_last_updated_ts\n",
    "    t.is_current = false\n",
    "\n",
    "WHEN NOT MATCHED BY TARGET\n",
    "THEN INSERT (bk, attr1, attr2, valid_from, valid_to, is_current)\n",
    "VALUES (s.bk, s.attr1, s.attr2, s.etl_run_ts, TIMESTAMP '9999-12-31', true);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e5f13b5-2a5e-4a0d-ae5b-3719715bb33e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "dim_path = \"/mnt/delta/dim_entity\"\n",
    "\n",
    "dim_delta = DeltaTable.forPath(spark, dim_path)\n",
    "\n",
    "src_df = (\n",
    "    src_raw_df\n",
    "    # keep one row per bk (e.g., latest by timestamp)\n",
    ")\n",
    "\n",
    "cond = \"t.bk = s.bk AND t.is_current = true\"\n",
    "\n",
    "change_expr = \"\"\"\n",
    "  t.attr1 <> s.attr1 OR t.attr2 <> s.attr2\n",
    "  OR (t.attr1 IS NULL AND s.attr1 IS NOT NULL)\n",
    "  OR (t.attr1 IS NOT NULL AND s.attr1 IS NULL)\n",
    "\"\"\"\n",
    "\n",
    "(dim_delta\n",
    " .alias(\"t\")\n",
    " .merge(src_df.alias(\"s\"), cond)\n",
    " .whenMatched(condition=change_expr)\n",
    " .update({\n",
    "     \"valid_to\":   col(\"s.etl_run_ts\"),\n",
    "     \"is_current\": lit(False)\n",
    " })\n",
    " .whenNotMatched()\n",
    " .insert({\n",
    "     \"bk\":         col(\"s.bk\"),\n",
    "     \"attr1\":      col(\"s.attr1\"),\n",
    "     \"attr2\":      col(\"s.attr2\"),\n",
    "     \"valid_from\": col(\"s.etl_run_ts\"),\n",
    "     \"valid_to\":   lit(\"9999-12-31\"),\n",
    "     \"is_current\": lit(True)\n",
    " })\n",
    " .execute()\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark_scd2_implementation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
