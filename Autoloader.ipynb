{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c465202-40fe-441e-835c-0c0b4cf959fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (spark.readStream\n",
    "  .format(\"cloudFiles\")\n",
    "  .option(\"cloudFiles.format\", \"json\")\n",
    "  .load(\"abfss://container@storageaccount.dfs.core.windows.net/input-path/\"))\n",
    "\n",
    "(df.writeStream\n",
    "  .format(\"delta\")\n",
    "  .option(\"checkpointLocation\", \"abfss://container@storageaccount.dfs.core.windows.net/checkpoints/\")\n",
    "  .start(\"abfss://container@storageaccount.dfs.core.windows.net/output-table/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10e6c3ff-fee4-4ad8-9710-28814bc35f36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Input path for JSON files (e.g., raw landing zone)\n",
    "input_path = \"abfss://container@storageaccount.dfs.core.windows.net/raw/json/\"\n",
    "\n",
    "# Schema evolution and checkpoint paths\n",
    "schema_location = \"abfss://container@storageaccount.dfs.core.windows.net/schema/\"\n",
    "checkpoint_location = \"abfss://container@storageaccount.dfs.core.windows.net/checkpoints/\"\n",
    "\n",
    "# Streaming DataFrame with Auto Loader\n",
    "raw_df = (spark.readStream\n",
    "  .format(\"cloudFiles\")\n",
    "  .option(\"cloudFiles.format\", \"json\")\n",
    "  .option(\"cloudFiles.schemaLocation\", schema_location)\n",
    "  .option(\"cloudFiles.schemaEvolutionMode\", \"rescue\")\n",
    "  .load(input_path)\n",
    ")\n",
    "\n",
    "# Optional: Apply transformations (e.g., parse nested JSON)\n",
    "# transformed_df = raw_df.select(...)\n",
    "\n",
    "# Write to Delta table\n",
    "query = (raw_df.writeStream\n",
    "  .format(\"delta\")\n",
    "  .outputMode(\"append\")\n",
    "  .option(\"checkpointLocation\", checkpoint_location)\n",
    "  .trigger(availableNow=True)  # For batch-like processing; use processingTime for continuous\n",
    "  .start(\"abfss://container@storageaccount.dfs.core.windows.net/delta/customers/\")\n",
    ")\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Autoloader",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
